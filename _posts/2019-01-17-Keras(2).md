---
tag: 机器学习
---





## 改版后的Keras 和以前有些差别





用在Keras(1)中的例子。



图片是28*28 pixels 的



两个隐藏层，分别有500个神经元



输出是10维的，输出层的Activation function 采用 Softmax







### 定义Function

```
//首先宣告一个model
model = Sequential()
```



```
//第一隐藏层
model.add(Dense(input_dim=28*28,units=500,activation='relu')) 
//Dense表示fully connected layer
//units 表示neuron的数目，这在Keras 1.0版本中是用 output_dim来表示的
//Keras 2.0 用一句话集成了 Activation function
//Activation function 还有： relu,softplus,softsign,sigmoid,tanh,hard_sigmoid,linear等
//如果要自己设计Activation function ，可以在Keras 设置Activation function的地方自己插入
```



```
//第二隐藏层
model.add(Dense(units=500,activation='relu'))
//第二层不用宣告 input_dim了因为就是前一层的units
```



```
//输出层
model.add(Dense(units=10,activation='softmax'))
//这里一定要是10维的
```





### Goodness of the Function

**Configuration，这里和Keras 1.0 一样**

```
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

//optimizer 有很多，例如: SGD,RMSprop,Adagrad,Adadelta,Adam,Adamax,Nadam
```



Loss Function 有很多[alternatives](https://keras.io/objectives)



### Pick the best function

```
model.fit(x_train,y_train,batch_size=100,epochs=20)  //四个参数

//x_train，几个样本就几行，几个features 就几列
//y_train，几个样本就几行，几个classfication就几列，中间有一个1
```





### 将模型保存下来

[官方文档](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model)





### 应用

#### 评价

```
score=model.evaluate(x_test,y_test)
print('Total loss on Testing Set:', score[0])
print('Accuracy of Testing Set:‘，score[1])




```

#### 使用

```
result = model.predict(x_test)
```

