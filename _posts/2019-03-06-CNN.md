---
tag: 机器学习
---





CNN--可以自己设计 neural network 架构、简化版的Fully connected neural network。

CNN(convolutional neural network)相比于Fully connected neural network在做法上有些不一样，结果是往往能得到比较好的performance、不容易overfitting、有比较小的variance。





## 设计CNN的motivation

CNN常常用在影像辨识上面。

> 以影像辨识为例

给machine一张image(pixels matrix)。目的是一个分类问题，来输出图片中的object是什么。

**问题是：有一些patterns非常小，只占整张图片的很小一部分。**


**一个neuron不需要去看整张图片来发现这个pattern**


![a1p2](https://wx3.sinaimg.cn/large/8f3e11fcgy1g0te6b59uej20n70gt41k.jpg)


比如说某个neuron是用来侦测鸟的嘴巴，当看到鸟嘴的时候就会有一个非常大的output给后面的neuron，再由后面的neuron来决定是不是一只鸟。


但是侦测鸟嘴不需要看整张image，只要看红色框框所框出来的部分就可以知道其是不是一个鸟嘴。




**同一个patterns会出现在一张图片的不同区域，他们的形状是相似的，用同一个neuron、同一组parameters就可以侦测出来。**




![a2p3](https://wx4.sinaimg.cn/large/8f3e11fcgy1g0te6nugf9j20ns0gjaej.jpg)


**一张image可以做subsampling,而不会改变它里面内容的形状。**



![a3p4](https://ws4.sinaimg.cn/large/8f3e11fcgy1g0te6w37sxj20n40gd0x6.jpg)


所以可以让影像变小来简化问题、减少参数。


## CNN架构

![a4p5](https://ws1.sinaimg.cn/large/8f3e11fcgy1g0te71vwr6j20n70hkwht.jpg)

上面讲的3个motivation对应的三个CNN性质、操作。
![a5p6](https://ws4.sinaimg.cn/large/8f3e11fcgy1g0te76xsavj20nl0h8q61.jpg)


## Convolution

> 以例子来说明具体操作



input a 黑白 image with 6乘6pixels.


* 现在有几个Filters，每个Filter用来检测不同的patterns（其实就是矩阵，形状自己设置，参数是根据training data训练出来的，类似FNN里面的weight。）

**Filters的size通常要大于某个pattern的大小，这样才能够detect出来。**







![a6p8](https://wx3.sinaimg.cn/large/8f3e11fcgy1g0te7f2fhmj20nh0hbdh0.jpg)





例如有个3乘3的Filter，那么说明要抓取的Pattern小于等于3乘3pixels。


![a7p11](https://wx4.sinaimg.cn/large/8f3e11fcgy1g0te7q0zqoj20n90hh40c.jpg)


* 用image从左上到右下的每3乘3pixels的区域与Filter做inner product。如果stride=1，那么每次Filter整体往右移动1个pixel。


全部扫完，得到右下图所示的一个矩阵。

再来看这个FIlter，斜对角上的数全是1，其他地方是-1，那么这个Filter所侦测的是从左上到右下值全为1的地方。（这样输出会比较大）。

所以原图左上和左下出现了2个3，就是这个Filter所要找的地方。

可以看到同一个pattern在左上或者左下（不同位置）都可以由同一个Filter（同一组参数）来找到。


* 现在用第二个不同的Filter来做同样的一件事，stride还是为1 。会得到蓝色圆圈的一个矩阵


![a8p12](https://ws4.sinaimg.cn/large/8f3e11fcgy1g0te7w7jc3j20nr0he0ur.jpg)


Convolution经过这两个Filter以后得到的东西，称之为Feature Map。

也可以看成是一张新的image，只不过这张image比较小；而且这张Image的每一个pixel有比较多的value来描述。

> 如果这张图片是彩色的图片（RGB彩色，即有3个channel）

* Filter 是一个立方体，3乘3乘3的。高度的3表示有几个channel。
![a9p13](https://ws1.sinaimg.cn/large/8f3e11fcgy1g0te8143saj20nl0gzdkx.jpg)



## Convolution v.s. Fully Connected



Convolution可以看成是Fully Connected的简化版。

将Feature Map这个output拉直想象成是图片经过Fully Connected里面的某一层以后得到的output，如下图。

![a10p14](https://ws3.sinaimg.cn/large/8f3e11fcgy1g0te87spp7j20nk0hgjtg.jpg)

![a11p15](https://ws2.sinaimg.cn/large/8f3e11fcgy1g0te8ctlesj20nn0hltbs.jpg)

![a12p16](https://wx2.sinaimg.cn/large/8f3e11fcgy1g0te8j38jnj20nr0hu780.jpg)

将某一个Filter里面的数字看成是FNN里面的权重，只是每个neuron只连接9个，减少了参数（其他的都可以看成是0），而且每个neuron共用(share)一组weight（对于该Filter），只是input不一样。这样也大大减少了参数（相对FNN）。


## MaxPooling

![a13p18](https://ws2.sinaimg.cn/large/8f3e11fcgy1g0te8o7ru2j20nn0h9taq.jpg)

由两个Filter经过Convolution得到了两个matrix。

MaxPooling要做的事情，是将这些Matrix分别group起来，例如每组4个（2乘2个数），在每组里面选一个最大的，就是MaxPooling。

和Maxout一样，这个operation可以求(偏)微分。


除了max pooling,还可以用比如说average pooling，将每组的平均值留下，当作output。两者没有哪一个比哪一个更好，也可以两者同时用上。就是每一个group选择两个数值作为output。


**经过Convolution和Max Pooling以后，得到的东西可以看成是一张新的，但是远比原来要小的image。**

**这张新的Image有几个channel就要看convolution layer里面有几个FIlter**




![a14p19](https://ws1.sinaimg.cn/large/8f3e11fcgy1g0te8t1ifej20nk0hl75q.jpg)



### Convolution+maxpooling 这一过程可以反复做数次。

![a15p20](https://wx3.sinaimg.cn/large/8f3e11fcgy1g0te8yashnj20ng0hb410.jpg)


## Flatten

当一张图片经过n次Convolution+Max Pooling得到一张够小的Image的时候，可以进行接下来的步骤：Flatten。




Flatten很简单，就是将最后得到的那张Image的每一个Pixel的每一个channel平铺、拉直。

![a16p22](https://wx2.sinaimg.cn/large/8f3e11fcgy1g0te94bjpij20ne0htq68.jpg)




## Fully Connected neural network

图片经过Flatten拉直以后，最后再输入FNN。训练的方法是Gradient Descent。



---



## 用Keras 2.0来做CNN

![a17p23](https://ws3.sinaimg.cn/large/8f3e11fcgy1g0te99p3t0j20nn0hrtbo.jpg)

![a18p24](https://ws3.sinaimg.cn/large/8f3e11fcgy1g0te9erd1zj20nr0hkdja.jpg)

```
//Convolution
model2.add( Convolution2D(25,3,3,input_shape=(28,28,1)) ) 
//25表示有25个Filter，Filter的大小是3乘3的。
//28表示Input image的大小(pixels)，1表示该Image的channel是1 ，这里表示黑白图片，彩色图片(RGB)就是3 。
```

```
//例如，输入一个28(pixels)*28(pixels)*1(channels)的image
//经过上面的convolution以后
//得到26(pixels)*26(pixels)*25(channels)，之所以是26是因为边边角角被去掉了，25是因为有25个Filter
```


```
//Max Pooling
model2.add(MaxPooling2D((2,2)) )
//2表示Group形状是2乘2的，即四个一组
```

**这个时候每一个Filter的参数是9个**

```
经过这一层以后，得到13(pixels)*13(pixels)*25(channel)的一个image
```

```
//反复这两个步骤
//再做一次convolution
model2.add(Convolution2D(50,3,3))
//原则上，通常CNN在设计Filter的时候，在靠近Input的地方Filter数目少，然后Filter会越来越多。
//某种原因：FIlter的作用是detect某种pattern。比较靠近input的时候是detect比较单纯的pattern，越到后面Filter是用来detect越来越抽象的Pattern。Basic的东西比较少，比如点、线、颜色。abstract 的东西很多，比如说狗、猫之类的无法穷举。所以在设计CNN的时候Pattern数目是由少到多。
```

**这一层Filter的参数个数是3乘3乘25=225个，因为Filter有高，是立体的**


```
///做完这一层，image的size变成11(pixels)*11(pixels)*50(channel)
```

```
//MaxPooling
model2.add(MaxPooling2D((2,2)) )
```

```
经过这一层，输出5(pixels)*5(pixels)*50(channel)的图片
```



**输出的channel个数和卷积层的channel一样**


```
//接下来做Flatten
model2.add(Flatten() )
```

将5乘5乘50=1250个数值丢给FNN

```
//以1层hidden layer为例
model2.add(Dense(output_dim=100) )
model2.add(Activation('relu') )
model2.add(Dense(output_dim=10) ) //在做图像辨识，所以output维度是10维
model2.add(Activation('softmax')  )
```

---


train完Network以后，整个deep network就好像是一个黑盒子，不知道他在干什么。不能只看他能够得到高的正确率，同时也要看machine为什么可以得到好的结果。




machine可以看到更深层次的东西。



* 可以直接把Filter(的参数)拿出来看看

> AlexNet的第一层Filter，这些Filter是作用在彩色图上，有深度信息的。




![b1p28](https://ws1.sinaimg.cn/large/8f3e11fcgy1g0te9lphh8j20nf0ha7av.jpg)


这些Filter是11(pixels)乘11(pixels)的。上面的一些FIlters的工作可以推测是用来侦测某种形状，下面的FIlters的工作可能是用来侦测某种颜色的存在。

但是通常只有第一层layer可以拿出来看他的参数，后面的layer拿出来看并没有太大的意义，因为第二层layer的input是第一层Layer的output，直接拿来看并不能看出来什么。



* 把很多张图片丢进CNN,看某个neuron(Filter)在什么时候activate最强。就可以知道他在做什么事情。

![b2p29](https://wx4.sinaimg.cn/large/8f3e11fcgy1g0tebnxbcmj20np0hlds6.jpg)


左上角的值是某个neuron activate的数值。白色的框框代表某个neuron 可以看到的区域。


这里应该是某个high layer的Filter，他所能够管辖看到的范围应该是比较大的。FIlter的layer越深感受野越大。


* 可以看经过某一层(第k个)Filter以后的输出

> e.g.

![b3p30](https://ws2.sinaimg.cn/large/8f3e11fcgy1g0tebu14s1j20ns0hngny.jpg)


例如，经过第二个convolution以后，对于每single Filter的输出是11(pixels)乘11(pixels)的。


定义一个东西叫做Degree of the activation of the k-th filter，就是把这个new image每一个Pixel数值相加。

$$
a^k=\sum^{11}_{i=1} \sum^{11}_{j=1} a^k_{ij}
$$


现在要找一个input x，使得

$$
x^* =\arg \max\limits_x a^k
$$

求这个input matrix x的方法就是Gradient Descent。

即只要计算

$$
\frac{\partial a^k}{\partial x_{ij}}
$$

用GD就能找到这个matrix。也就是把network的参数固定，但是把input matrix x当作是参数，然后来找这个参数，能够Maximize这个
$$
a^k
$$

> e.g. 有一个做好的结果(左下角)，是前12个Filter做出来的结果。


![b4p31](https://ws2.sinaimg.cn/large/8f3e11fcgy1g0tec5myeej20ni0h8gq8.jpg)


可以看到第一张图是最能够让第一个Filter activate的。


* 分析Fully Connected的部分

和刚才类似

![b5p32](https://wx4.sinaimg.cn/large/8f3e11fcgy1g0tecbft55j20nm0hiwj4.jpg)

只是这里是相加一排
$$
a^j
$$
，而非一个长方形。

要做的事情是要找到一个input matrix x，使得，FNN中的某个neuron的输出达到最大。方法依然是GD。


* 现在来看FNN最后的输出(在该手写数字辨识中是10维的)

![b6p33](https://ws3.sinaimg.cn/large/8f3e11fcgy1g0tecgpmdxj20nl0hf0yc.jpg)

要找一个input matrix x，使得最终FNN output所对应的某一个数字的值最大。


$$
x^*=\arg \max\limits_x y^i
$$

找到的input matrix 并不是一些数字，而是如图所示，类似电视机没信号的时候的图像。



这里可以看出这个network很容易被欺骗。


* 可以把上面的结果做得更好

在做arg这个operation的时候，添加一个l1 regularization的项。使得这个input matrix x要同时照顾到两者。

**这里的公式应该是减？**



$$
x^* =\arg \max\limits_x (y^i+\sum_{i,j} \lvert x_{ij} \rvert)
$$


这样就能够使得要求出的input matrix x尽可能涂黑，只有在必要的时候涂白。

这样做出来的结果如下右图所示：

![b7p34](https://wx1.sinaimg.cn/large/8f3e11fcgy1g0tecmy9g2j20nn0gyq7b.jpg)


结果稍稍变好。


### 要看出某个神经网络要从一张图片的哪个地方看出来这张图片是什么东西

* 可以求每一个像素点对输出的偏微分

$$
\lvert \frac{\partial y_k}{\partial x_{ij}} \rvert
$$


看哪些部分的偏微分值大。但是这样做会很麻烦。


![b8p36](https://wx3.sinaimg.cn/large/8f3e11fcgy1g0tecrwcvvj20nm0hhaiv.jpg)


* 可以遮住Image的某一小部分，看输出

![b9p37](https://wx4.sinaimg.cn/large/8f3e11fcgy1g0tecwzry1j20nn0hdgs9.jpg)



---

## Application

### Deep Dream

给定一张图片，让机器来增加内容




### Deep Style 

给定一张图片，让这张图片的风格变成其他的名画。

> gradient ascend: 探究输入图形的像素对输出结果的梯度，用来找到最佳图像


文献参考：[A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576)


做法：

1. 训练1个CNN来输出content(内容)
2. 训练1个CNN来输出style(风格)
3. 找一个input matrix x，使得x从content来看像第一个，从style来看像第二个。


### Playing Go：



input：一张棋盘

中间通过一个很深的Neural Network。FNN可以用，但是CNN表现好得多。


output：Next move



**可以把整张棋盘看成一张19(pixels)乘19(pixels)的image。**记黑子为1，白子为-1，没有子为0 。

训练方法：找一些棋谱(image)，通过CNN,Next move的label为1 。


使用CNN的好处：
1. Some patterns are much smaller than the whole image.(Alpha Go uses 5乘5 for first layer.
2. The same patterns appear in different regions.


**注意：在这里CNN不能够加上Max Pooling,因为棋盘不能够被抽取掉奇数（偶数）行列。**

![b10p46](https://wx1.sinaimg.cn/large/8f3e11fcgy1g0ted3g1g6j20ny0hpjxi.jpg)


注意：Alpha Go 将images的边边角角给补上去了，防止在经过FIlter的时候将边边角角的地方去掉。

**设计network structure的时候要充分考虑task的特性**

### 语音辨识

![b11p47](https://ws4.sinaimg.cn/large/8f3e11fcgy1g0ted7a4a7j20nm0hawn0.jpg)


横轴时间，纵轴看成频率，整个就是一张Image。


